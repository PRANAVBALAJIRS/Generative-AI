{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc17712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958151af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\prana\\\\Downloads\\\\SourceCode Analysis\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6898b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir test_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b052d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"test_repo/\"\n",
    "repo = Repo.clone_from(\"https://github.com/PRANAVBALAJIRS/VisionRevive\", to_path=repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1a6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(repo_path,\n",
    "                                       glob = \"**/*\",\n",
    "                                       suffixes=[\".py\"],\n",
    "                                       parser = LanguageParser(language=Language.PYTHON, parser_threshold=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d9d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db271178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"from setuptools import setup, find_packages\\n\\nsetup(\\n    name='ffa_net_project',\\n    version='0.1',\\n    packages=find_packages('src'),\\n    package_dir={'': 'src'},\\n    install_requires=[\\n        'numpy',\\n        'torch',\\n        'scikit-learn',\\n        'matplotlib',\\n        'pandas',\\n    ],\\n    entry_points={\\n        'console_scripts': [\\n            'ffa_net=src.main:main',\\n        ],\\n    },\\n)\\n\", metadata={'source': 'test_repo\\\\setup.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import os, sys\\nimport time, math\\nimport argparse, random\\nfrom math import exp\\nimport numpy as np\\n\\nimport torch\\nfrom torch import nn, optim\\nimport torch.nn.functional as F\\nimport torch.utils.data as data\\nfrom torch.utils.data import DataLoader\\nfrom torch.backends import cudnn\\nfrom torch.autograd import Variable\\n\\nimport torchvision\\nimport torchvision.transforms as tfs\\nfrom torchvision.transforms import ToPILImage\\nfrom torchvision.transforms import functional as FF\\nimport torchvision.utils as vutils\\nfrom torchvision.utils import make_grid\\nfrom torchvision.models import vgg16\\n\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings(\\'ignore\\')\\n\\nsteps = 20000\\ndevice = \\'cuda\\' if torch.cuda.is_available() else \\'cpu\\'\\nresume = False\\neval_step = 5000\\nlearning_rate = 0.0001\\npretrained_model_dir = \\'../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/\\'\\nmodel_dir = \\'./trained_models/\\'\\ntrainset = \\'its_train\\'\\ntestset = \\'its_test\\'\\nnetwork = \\'ffa\\'\\ngps = 3\\nblocks = 5\\nbs = 1\\ncrop = True\\ncrop_size = 240\\nno_lr_sche = True\\nperloss = True\\n\\nmodel_name = f\"{trainset}_{network.split(\\'.\\')[0]}_{gps}_{blocks}\"\\npretrained_model_dir += model_name + \\'.pk\\'\\nmodel_dir += model_name + \\'.pk\\'\\nlog_dir = f\\'logs/{model_name}\\'\\n\\nfor directory in [\\'trained_models\\', \\'numpy_files\\', \\'logs\\', \\'samples\\']:\\n    if not os.path.exists(directory):\\n        os.mkdir(directory)\\n\\nif not os.path.exists(f\"samples/{model_name}\"):\\n    os.mkdir(f\\'samples/{model_name}\\')\\n\\nif not os.path.exists(log_dir):\\n    os.mkdir(log_dir)\\n\\ncrop_size = \\'whole_img\\' if crop else crop_size', metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class RESIDE_Dataset(torch.utils.data.Dataset):\\n    def __init__(self, path, train, size=crop_size, format=\\'.png\\'):\\n        super(RESIDE_Dataset, self).__init__()\\n        self.size = size\\n        self.train = train\\n        self.format = format\\n        self.haze_imgs_dir = os.listdir(os.path.join(path, \\'hazy\\'))\\n        self.haze_imgs = [os.path.join(path, \\'hazy\\', img) for img in self.haze_imgs_dir]\\n        self.clear_dir = os.path.join(path, \\'clear\\')\\n\\n    def __getitem__(self, index):\\n        haze = Image.open(self.haze_imgs[index])\\n        if isinstance(self.size, int):\\n            while haze.size[0] < self.size or haze.size[1] < self.size:\\n                index = random.randint(0, 20000)\\n                haze = Image.open(self.haze_imgs[index])\\n        img = self.haze_imgs[index]\\n        id = img.split(\\'/\\')[-1].split(\\'_\\')[0]\\n        clear_name = id + self.format\\n        clear = Image.open(os.path.join(self.clear_dir, clear_name))\\n        clear = tfs.CenterCrop(haze.size[::-1])(clear)\\n        if not isinstance(self.size, str):\\n            i, j, h, w = tfs.RandomCrop.get_params(haze, output_size=(self.size, self.size))\\n            haze = tfs.functional.crop(haze, i, j, h, w)\\n            clear = tfs.functional.crop(clear, i, j, h, w)\\n        haze, clear = self.augData(haze.convert(\"RGB\"), clear.convert(\"RGB\"))\\n        return haze, clear\\n\\n    def augData(self, data, target):\\n        if self.train:\\n            rand_hor = random.randint(0, 1)\\n            rand_rot = random.randint(0, 3)\\n            data = tfs.RandomHorizontalFlip(rand_hor)(data)\\n            target = tfs.RandomHorizontalFlip(rand_hor)(target)\\n            if rand_rot:\\n                data = tfs.functional.rotate(data, 90 * rand_rot)\\n                target = tfs.functional.rotate(target, 90 * rand_rot)\\n        data = tfs.ToTensor()(data)\\n        data = tfs.Normalize(mean=[0.64, 0.6, 0.58], std=[0.14, 0.15, 0.152])(data)\\n        target = tfs.ToTensor()(target)\\n        return data, target\\n\\n    def __len__(self):\\n        return len(self.haze_imgs)\\n\\nits_train_path = \\'../input/indoor-training-set-its-residestandard\\'\\nits_test_path = \\'../input/synthetic-objective-testing-set-sots-reside/indoor\\'\\n\\nITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\\nITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size=\\'whole img\\'), batch_size=16, shuffle=False)', metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class PerLoss(torch.nn.Module):\\n    def __init__(self, vgg_model):\\n        super(PerLoss, self).__init__()\\n        self.vgg_layers = vgg_model\\n        self.layer_name_mapping = {\\n            \\'3\\': \"relu1_2\",\\n            \\'8\\': \"relu2_2\",\\n            \\'15\\': \"relu3_3\"\\n        }\\n\\n    def output_features(self, x):\\n        output = {}\\n        for name, module in self.vgg_layers._modules.items():\\n            x = module(x)\\n            if name in self.layer_name_mapping:\\n                output[self.layer_name_mapping[name]] = x\\n        return list(output.values())\\n\\n    def forward(self, dehaze, gt):\\n        loss = []\\n        dehaze_features = self.output_features(dehaze)\\n        gt_features = self.output_features(gt)\\n        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\\n            loss.append(F.mse_loss(dehaze_feature, gt_feature))\\n\\n        return sum(loss)/len(loss)', metadata={'source': 'test_repo\\\\src\\\\loss.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def main():\\n    print(\"Welcome to the FFA-Net Project\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n', metadata={'source': 'test_repo\\\\src\\\\main.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def test(net, loader_test, max_psnr, max_ssim, step):\\n    net.eval()\\n    torch.cuda.empty_cache()\\n    ssims, psnrs = [], []\\n    for i, (inputs, targets) in enumerate(loader_test):\\n        inputs = inputs.to(device); targets = targets.to(device)\\n        pred = net(inputs)\\n        # # print(pred)\\n        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save(\\'111.png\\')\\n        # vutils.save_image(targets.cpu(),\\'target.png\\')\\n        # vutils.save_image(pred.cpu(),\\'pred.png\\')\\n        ssim1 = ssim(pred, targets).item()\\n        psnr1 = psnr(pred, targets)\\n        ssims.append(ssim1)\\n        psnrs.append(psnr1)\\n        #if (psnr1>max_psnr or ssim1 > max_ssim) and s :\\n#             ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\\n#             vutils.save_image(ts,f\\'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png\\')\\n#             s=False\\n    return np.mean(ssims) ,np.mean(psnrs)\\n\\ntask = \\'its\\'\\ntest_imgs = \\'../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/\\'\\n\\ndataset = task\\nimg_dir = test_imgs\\n\\noutput_dir = f\\'pred_FFA_{dataset}/\\'\\nprint(\"pred_dir:\",output_dir)\\n\\nif not os.path.exists(output_dir):\\n    os.mkdir(output_dir)\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nprint(f\"Using device: {device}\")\\n\\nckp = torch.load(model_dir, map_location=device)\\nnet = FFA(gps=gps, blocks=blocks)\\nnet = nn.DataParallel(net)\\nnet.load_state_dict(ckp[\\'model\\'])\\nnet.to(device)  # Ensure the model is on the right device\\nnet.eval()\\n\\nfor im in os.listdir(img_dir):\\n    haze = Image.open(img_dir+im)\\n    haze1 = tfs.Compose([\\n        tfs.ToTensor(),\\n        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\\n    ])(haze)[None,::]\\n    \\n    haze1 = haze1.to(device)\\n    haze_no = tfs.ToTensor()(haze)[None,::]\\n    \\n    with torch.no_grad():\\n        pred = net(haze1)\\n    \\n    ts = torch.squeeze(pred.clamp(0,1).cpu())\\n    \\n    haze_no = make_grid(haze_no, nrow=1, normalize=True)\\n    ts = make_grid(ts, nrow=1, normalize=True)\\n    image_grid = torch.cat((haze_no, ts), -1)\\n    vutils.save_image(image_grid, output_dir + im.split(\\'.\\')[0] + \\'_FFA.png\\')', metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='print(\\'log_dir :\\', log_dir)\\nprint(\\'model_name:\\', model_name)\\n\\nmodels_ = {\\'ffa\\': FFA(gps = gps, blocks = blocks)}\\nloaders_ = {\\'its_train\\': ITS_train_loader, \\'its_test\\': ITS_test_loader}\\n# loaders_ = {\\'its_train\\': ITS_train_loader, \\'its_test\\': ITS_test_loader, \\'ots_train\\': OTS_train_loader, \\'ots_test\\': OTS_test_loader}\\nstart_time = time.time()\\nT = steps\\n\\ndef train(net, loader_train, loader_test, optim, criterion):\\n    losses = []\\n    start_step = 0\\n    max_ssim = max_psnr = 0\\n    ssims, psnrs = [], []\\n    if resume and os.path.exists(pretrained_model_dir):\\n        print(f\\'resume from {pretrained_model_dir}\\')\\n        ckp = torch.load(pretrained_model_dir)\\n        losses = ckp[\\'losses\\']\\n        net.load_state_dict(ckp[\\'model\\'])\\n        start_step = ckp[\\'step\\']\\n        max_ssim = ckp[\\'max_ssim\\']\\n        max_psnr = ckp[\\'max_psnr\\']\\n        psnrs = ckp[\\'psnrs\\']\\n        ssims = ckp[\\'ssims\\']\\n        print(f\\'Resuming training from step: {start_step} ***\\')\\n    else :\\n        print(\\'Training from scratch *** \\')\\n    for step in range(start_step+1, steps+1):\\n        net.train()\\n        accumulation_steps = 4\\n        lr = learning_rate\\n        if not no_lr_sche:\\n            lr = lr_schedule_cosdecay(step,T)\\n            for param_group in optim.param_groups:\\n                param_group[\"lr\"] = lr\\n        x, y = next(iter(loader_train))\\n        x = x.to(device); y = y.to(device)\\n        torch.cuda.empty_cache()\\n        out = net(x)\\n        loss = criterion[0](out,y)\\n#         loss = loss / accumulation_steps\\n#             loss.backward()  # Accumulate gradients\\n#             if (i + 1) % accumulation_steps == 0:  # Perform optimizer step every accumulation_steps\\n#                 optimizer.step()\\n#                 optimizer.zero_grad()\\n        if perloss:\\n            loss2 = criterion[1](out,y)\\n            loss = loss + 0.04*loss2\\n\\n        loss.backward()\\n\\n        optim.step()\\n        optim.zero_grad()\\n        losses.append(loss.item())\\n        print(f\\'\\\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}\\',end=\\'\\',flush=True)\\n        if step % eval_step ==0 :\\n            with torch.no_grad():\\n                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\\n            print(f\\'\\\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}\\')\\n\\n            ssims.append(ssim_eval)\\n            psnrs.append(psnr_eval)\\n            if ssim_eval > max_ssim and psnr_eval > max_psnr :\\n                max_ssim = max(max_ssim,ssim_eval)\\n                max_psnr = max(max_psnr,psnr_eval)\\n                torch.save({\\n                            \\'step\\': step,\\n                            \\'max_psnr\\': max_psnr,\\n                            \\'max_ssim\\': max_ssim,\\n                            \\'ssims\\': ssims,\\n                            \\'psnrs\\': psnrs,\\n                            \\'losses\\': losses,\\n                            \\'model\\': net.state_dict()\\n                }, model_dir)\\n                print(f\\'\\\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}\\')\\n\\n    np.save(f\\'./numpy_files/{model_name}_{steps}_losses.npy\\',losses)\\n    np.save(f\\'./numpy_files/{model_name}_{steps}_ssims.npy\\',ssims)\\n    np.save(f\\'./numpy_files/{model_name}_{steps}_psnrs.npy\\',psnrs)\\n\\n%%time\\n\\nloader_train = loaders_[trainset]\\nloader_test = loaders_[testset]\\nnet = models_[network]\\nnet = net.to(device)\\nif device == \\'cuda\\':\\n    net = torch.nn.DataParallel(net)\\n    cudnn.benchmark = True\\ncriterion = []\\ncriterion.append(nn.L1Loss().to(device))\\nif perloss:\\n    vgg_model = vgg16(pretrained=True).features[:16]\\n    vgg_model = vgg_model.to(device)\\n    for param in vgg_model.parameters():\\n        param.requires_grad = False\\n    criterion.append(PerLoss(vgg_model).to(device))\\noptimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\\noptimizer.zero_grad()\\ntrain(net, loader_train, loader_test, optimizer, criterion)', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='', metadata={'source': 'test_repo\\\\src\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class PALayer(nn.Module):\\n    def __init__(self, channel):\\n        super(PALayer, self).__init__()\\n        self.pa = nn.Sequential(\\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\\n                nn.ReLU(inplace=True),\\n                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\\n                nn.Sigmoid()\\n        )\\n    def forward(self, x):\\n        y = self.pa(x)\\n        return x * y\\n    \\nclass CALayer(nn.Module):\\n    def __init__(self, channel):\\n        super(CALayer, self).__init__()\\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\\n        self.ca = nn.Sequential(\\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\\n                nn.ReLU(inplace=True),\\n                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\\n                nn.Sigmoid()\\n        )\\n\\n    def forward(self, x):\\n        y = self.avg_pool(x)\\n        y = self.ca(y)\\n        return x * y\\n    \\nclass EfficientAttention(nn.Module):\\n    def __init__(self, channel):\\n        super(EfficientAttention, self).__init__()\\n        self.conv1 = nn.Conv2d(channel, channel, kernel_size=1, bias=False)\\n        self.conv2 = nn.Conv2d(channel, channel, kernel_size=1, bias=False)\\n        self.sigmoid = nn.Sigmoid()\\n    \\n    def forward(self, x):\\n        attn_map = self.sigmoid(self.conv1(x))\\n        refined = attn_map * self.conv2(x)\\n        return refined', metadata={'source': 'test_repo\\\\src\\\\model\\\\attention_mechanisms.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class Block(nn.Module):\\n    def __init__(self, conv, dim, kernel_size):\\n        super(Block, self).__init__()\\n        self.conv1 = conv(dim, dim, kernel_size, bias=True)\\n        self.act1 = nn.ReLU(inplace=True)\\n        self.conv2 = conv(dim, dim, kernel_size, bias=True)\\n        \\n        self.calayer = CALayer(dim) \\n        self.palayer = PALayer(dim)  \\n        self.efficient_attention = EfficientAttention(dim) \\n        self.progressive_refinement = ProgressiveAttentionRefinement(dim) \\n        \\n    def forward(self, x):\\n        res = self.act1(self.conv1(x))\\n        res = res + x\\n        \\n        res = self.conv2(res)\\n        \\n        res = self.calayer(res)\\n        res = self.palayer(res)\\n        res = self.efficient_attention(res)\\n        res = self.progressive_refinement(res)\\n        \\n        res += x\\n        return res\\n\\nclass Group(nn.Module):\\n    def __init__(self, conv, dim, kernel_size, blocks):\\n        super(Group, self).__init__()\\n        modules = [Block(conv, dim, kernel_size) for _ in range(blocks)]\\n        modules.append(conv(dim, dim, kernel_size))\\n        self.gp = nn.Sequential(*modules)\\n\\n    def forward(self, x):\\n        res = self.gp(x)\\n        res += x\\n        return res\\n    \\nclass FFA(nn.Module):\\n    def __init__(self, gps, blocks, conv=default_conv):\\n        super(FFA, self).__init__()\\n        self.gps = gps\\n        self.dim = 64\\n        kernel_size = 3\\n        pre_process = [conv(3, self.dim, kernel_size)]\\n        assert self.gps == 3\\n        self.g1 = Group(conv, self.dim, kernel_size, blocks=blocks)\\n        self.g2 = Group(conv, self.dim, kernel_size, blocks=blocks)\\n        self.g3 = Group(conv, self.dim, kernel_size, blocks=blocks)\\n        self.ca = nn.Sequential(\\n            nn.AdaptiveAvgPool2d(1),\\n            nn.Conv2d(self.dim * self.gps, self.dim // 16, 1, padding=0),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(self.dim // 16, self.dim * self.gps, 1, padding=0, bias=True),\\n            nn.Sigmoid()\\n        )\\n        self.palayer = PALayer(self.dim)\\n\\n        post_process = [\\n            conv(self.dim, self.dim, kernel_size),\\n            conv(self.dim, 3, kernel_size)\\n        ]\\n\\n        self.pre = nn.Sequential(*pre_process)\\n        self.post = nn.Sequential(*post_process)\\n\\n    def forward(self, x1):\\n        x = self.pre(x1)\\n        res1 = self.g1(x)\\n        res2 = self.g2(res1)\\n        res3 = self.g3(res2)\\n        w = self.ca(torch.cat([res1, res2, res3], dim=1))\\n        w = w.view(-1, self.gps, self.dim)[:, :, :, None, None]\\n        out = w[:, 0, :] * res1 + w[:, 1, :] * res2 + w[:, 2, :] * res3\\n        out = self.palayer(out)\\n        x = self.post(out)\\n        return x + x1', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class ProgressiveAttentionRefinement(nn.Module):\\n    def __init__(self, channels):\\n        super(ProgressiveAttentionRefinement, self).__init__()\\n        self.ca = nn.Sequential(\\n            nn.Conv2d(channels, channels // 8, kernel_size=1, bias=True),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(channels // 8, channels, kernel_size=1, bias=True),\\n            nn.Sigmoid()\\n        )\\n        self.pa = nn.Sequential(\\n            nn.Conv2d(channels, 1, kernel_size=1, bias=True),\\n            nn.Sigmoid()\\n        )\\n    \\n    def forward(self, x):\\n        ca_weight = self.ca(x)\\n        pa_weight = self.pa(x)\\n        return x * ca_weight * pa_weight', metadata={'source': 'test_repo\\\\src\\\\model\\\\progressive_attention.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='', metadata={'source': 'test_repo\\\\src\\\\model\\\\__init__.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def tensorShow(tensors, titles=None):\\n    fig = plt.figure()\\n    for tensor, title, i in zip(tensors, titles, range(len(tensors))):\\n        img = make_grid(tensor)\\n        npimg = img.numpy()\\n        ax = fig.add_subplot(211 + i)\\n        ax.imshow(np.transpose(npimg, (1, 2, 0)))\\n        ax.set_title(title)\\n    plt.show()\\n\\ndef lr_schedule_cosdecay(t, T, init_lr=learning_rate):\\n    lr = 0.5 * (1 + math.cos(t * math.pi / T)) * init_lr\\n    return lr\\n\\n', metadata={'source': 'test_repo\\\\src\\\\utils\\\\helpers.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def gaussian(window_size, sigma):\\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\\n    return gauss / gauss.sum()\\n\\ndef create_window(window_size, channel):\\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\\n    return window\\n\\ndef _ssim(img1, img2, window, window_size, channel, size_average=True):\\n    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\\n    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\\n    mu1_sq = mu1.pow(2)\\n    mu2_sq = mu2.pow(2)\\n    mu1_mu2 = mu1 * mu2\\n    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\\n    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\\n    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\\n    C1 = 0.01 ** 2\\n    C2 = 0.03 ** 2\\n    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\\n\\n    if size_average:\\n        return ssim_map.mean()\\n    else:\\n        return ssim_map.mean(1).mean(1).mean(1)\\n\\ndef ssim(img1, img2, window_size=11, size_average=True):\\n    img1=torch.clamp(img1,min=0,max=1)\\n    img2=torch.clamp(img2,min=0,max=1)\\n    (_, channel, _, _) = img1.size()\\n    window = create_window(window_size, channel)\\n    if img1.is_cuda:\\n        window = window.cuda(img1.get_device())\\n    window = window.type_as(img1)\\n    return _ssim(img1, img2, window, window_size, channel, size_average)\\n\\ndef psnr(pred, gt):\\n    pred=pred.clamp(0,1).cpu().numpy()\\n    gt=gt.clamp(0,1).cpu().numpy()\\n    imdff = pred - gt\\n    rmse = math.sqrt(np.mean(imdff ** 2))\\n    if rmse == 0:\\n        return 100\\n    return 20 * math.log10( 1.0 / rmse)', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='', metadata={'source': 'test_repo\\\\src\\\\utils\\\\__init__.py', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f9b677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb1ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON,\n",
    "                                                                 chunk_size = 500,\n",
    "                                                                 chunk_overlap = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96837694",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = document_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b821d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"from setuptools import setup, find_packages\\n\\nsetup(\\n    name='ffa_net_project',\\n    version='0.1',\\n    packages=find_packages('src'),\\n    package_dir={'': 'src'},\\n    install_requires=[\\n        'numpy',\\n        'torch',\\n        'scikit-learn',\\n        'matplotlib',\\n        'pandas',\\n    ],\\n    entry_points={\\n        'console_scripts': [\\n            'ffa_net=src.main:main',\\n        ],\\n    },\\n)\", metadata={'source': 'test_repo\\\\setup.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='import os, sys\\nimport time, math\\nimport argparse, random\\nfrom math import exp\\nimport numpy as np\\n\\nimport torch\\nfrom torch import nn, optim\\nimport torch.nn.functional as F\\nimport torch.utils.data as data\\nfrom torch.utils.data import DataLoader\\nfrom torch.backends import cudnn\\nfrom torch.autograd import Variable', metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"import torchvision\\nimport torchvision.transforms as tfs\\nfrom torchvision.transforms import ToPILImage\\nfrom torchvision.transforms import functional as FF\\nimport torchvision.utils as vutils\\nfrom torchvision.utils import make_grid\\nfrom torchvision.models import vgg16\\n\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\nimport warnings\\nwarnings.filterwarnings('ignore')\", metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"steps = 20000\\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\\nresume = False\\neval_step = 5000\\nlearning_rate = 0.0001\\npretrained_model_dir = '../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/'\\nmodel_dir = './trained_models/'\\ntrainset = 'its_train'\\ntestset = 'its_test'\\nnetwork = 'ffa'\\ngps = 3\\nblocks = 5\\nbs = 1\\ncrop = True\\ncrop_size = 240\\nno_lr_sche = True\\nperloss = True\", metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='model_name = f\"{trainset}_{network.split(\\'.\\')[0]}_{gps}_{blocks}\"\\npretrained_model_dir += model_name + \\'.pk\\'\\nmodel_dir += model_name + \\'.pk\\'\\nlog_dir = f\\'logs/{model_name}\\'\\n\\nfor directory in [\\'trained_models\\', \\'numpy_files\\', \\'logs\\', \\'samples\\']:\\n    if not os.path.exists(directory):\\n        os.mkdir(directory)\\n\\nif not os.path.exists(f\"samples/{model_name}\"):\\n    os.mkdir(f\\'samples/{model_name}\\')\\n\\nif not os.path.exists(log_dir):\\n    os.mkdir(log_dir)', metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"crop_size = 'whole_img' if crop else crop_size\", metadata={'source': 'test_repo\\\\src\\\\config.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"class RESIDE_Dataset(torch.utils.data.Dataset):\\n    def __init__(self, path, train, size=crop_size, format='.png'):\\n        super(RESIDE_Dataset, self).__init__()\\n        self.size = size\\n        self.train = train\\n        self.format = format\\n        self.haze_imgs_dir = os.listdir(os.path.join(path, 'hazy'))\\n        self.haze_imgs = [os.path.join(path, 'hazy', img) for img in self.haze_imgs_dir]\\n        self.clear_dir = os.path.join(path, 'clear')\", metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"def __getitem__(self, index):\\n        haze = Image.open(self.haze_imgs[index])\\n        if isinstance(self.size, int):\\n            while haze.size[0] < self.size or haze.size[1] < self.size:\\n                index = random.randint(0, 20000)\\n                haze = Image.open(self.haze_imgs[index])\\n        img = self.haze_imgs[index]\\n        id = img.split('/')[-1].split('_')[0]\\n        clear_name = id + self.format\\n        clear = Image.open(os.path.join(self.clear_dir, clear_name))\", metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='clear = tfs.CenterCrop(haze.size[::-1])(clear)\\n        if not isinstance(self.size, str):\\n            i, j, h, w = tfs.RandomCrop.get_params(haze, output_size=(self.size, self.size))\\n            haze = tfs.functional.crop(haze, i, j, h, w)\\n            clear = tfs.functional.crop(clear, i, j, h, w)\\n        haze, clear = self.augData(haze.convert(\"RGB\"), clear.convert(\"RGB\"))\\n        return haze, clear', metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def augData(self, data, target):\\n        if self.train:\\n            rand_hor = random.randint(0, 1)\\n            rand_rot = random.randint(0, 3)\\n            data = tfs.RandomHorizontalFlip(rand_hor)(data)\\n            target = tfs.RandomHorizontalFlip(rand_hor)(target)\\n            if rand_rot:\\n                data = tfs.functional.rotate(data, 90 * rand_rot)\\n                target = tfs.functional.rotate(target, 90 * rand_rot)\\n        data = tfs.ToTensor()(data)', metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='data = tfs.Normalize(mean=[0.64, 0.6, 0.58], std=[0.14, 0.15, 0.152])(data)\\n        target = tfs.ToTensor()(target)\\n        return data, target', metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"def __len__(self):\\n        return len(self.haze_imgs)\\n\\nits_train_path = '../input/indoor-training-set-its-residestandard'\\nits_test_path = '../input/synthetic-objective-testing-set-sots-reside/indoor'\\n\\nITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\\nITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size='whole img'), batch_size=16, shuffle=False)\", metadata={'source': 'test_repo\\\\src\\\\data_loader.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class PerLoss(torch.nn.Module):\\n    def __init__(self, vgg_model):\\n        super(PerLoss, self).__init__()\\n        self.vgg_layers = vgg_model\\n        self.layer_name_mapping = {\\n            \\'3\\': \"relu1_2\",\\n            \\'8\\': \"relu2_2\",\\n            \\'15\\': \"relu3_3\"\\n        }', metadata={'source': 'test_repo\\\\src\\\\loss.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def output_features(self, x):\\n        output = {}\\n        for name, module in self.vgg_layers._modules.items():\\n            x = module(x)\\n            if name in self.layer_name_mapping:\\n                output[self.layer_name_mapping[name]] = x\\n        return list(output.values())', metadata={'source': 'test_repo\\\\src\\\\loss.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def forward(self, dehaze, gt):\\n        loss = []\\n        dehaze_features = self.output_features(dehaze)\\n        gt_features = self.output_features(gt)\\n        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\\n            loss.append(F.mse_loss(dehaze_feature, gt_feature))\\n\\n        return sum(loss)/len(loss)', metadata={'source': 'test_repo\\\\src\\\\loss.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def main():\\n    print(\"Welcome to the FFA-Net Project\")\\n\\nif __name__ == \"__main__\":\\n    main()', metadata={'source': 'test_repo\\\\src\\\\main.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"def test(net, loader_test, max_psnr, max_ssim, step):\\n    net.eval()\\n    torch.cuda.empty_cache()\\n    ssims, psnrs = [], []\\n    for i, (inputs, targets) in enumerate(loader_test):\\n        inputs = inputs.to(device); targets = targets.to(device)\\n        pred = net(inputs)\\n        # # print(pred)\\n        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\\n        # vutils.save_image(targets.cpu(),'target.png')\\n        # vutils.save_image(pred.cpu(),'pred.png')\", metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"ssim1 = ssim(pred, targets).item()\\n        psnr1 = psnr(pred, targets)\\n        ssims.append(ssim1)\\n        psnrs.append(psnr1)\\n        #if (psnr1>max_psnr or ssim1 > max_ssim) and s :\\n#             ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\\n#             vutils.save_image(ts,f'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png')\\n#             s=False\\n    return np.mean(ssims) ,np.mean(psnrs)\", metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='task = \\'its\\'\\ntest_imgs = \\'../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/\\'\\n\\ndataset = task\\nimg_dir = test_imgs\\n\\noutput_dir = f\\'pred_FFA_{dataset}/\\'\\nprint(\"pred_dir:\",output_dir)\\n\\nif not os.path.exists(output_dir):\\n    os.mkdir(output_dir)\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\nprint(f\"Using device: {device}\")', metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"ckp = torch.load(model_dir, map_location=device)\\nnet = FFA(gps=gps, blocks=blocks)\\nnet = nn.DataParallel(net)\\nnet.load_state_dict(ckp['model'])\\nnet.to(device)  # Ensure the model is on the right device\\nnet.eval()\", metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='for im in os.listdir(img_dir):\\n    haze = Image.open(img_dir+im)\\n    haze1 = tfs.Compose([\\n        tfs.ToTensor(),\\n        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\\n    ])(haze)[None,::]\\n    \\n    haze1 = haze1.to(device)\\n    haze_no = tfs.ToTensor()(haze)[None,::]\\n    \\n    with torch.no_grad():\\n        pred = net(haze1)\\n    \\n    ts = torch.squeeze(pred.clamp(0,1).cpu())\\n    \\n    haze_no = make_grid(haze_no, nrow=1, normalize=True)', metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"ts = make_grid(ts, nrow=1, normalize=True)\\n    image_grid = torch.cat((haze_no, ts), -1)\\n    vutils.save_image(image_grid, output_dir + im.split('.')[0] + '_FFA.png')\", metadata={'source': 'test_repo\\\\src\\\\test.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"print('log_dir :', log_dir)\\nprint('model_name:', model_name)\\n\\nmodels_ = {'ffa': FFA(gps = gps, blocks = blocks)}\\nloaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader}\\n# loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader, 'ots_train': OTS_train_loader, 'ots_test': OTS_test_loader}\\nstart_time = time.time()\\nT = steps\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"def train(net, loader_train, loader_test, optim, criterion):\\n    losses = []\\n    start_step = 0\\n    max_ssim = max_psnr = 0\\n    ssims, psnrs = [], []\\n    if resume and os.path.exists(pretrained_model_dir):\\n        print(f'resume from {pretrained_model_dir}')\\n        ckp = torch.load(pretrained_model_dir)\\n        losses = ckp['losses']\\n        net.load_state_dict(ckp['model'])\\n        start_step = ckp['step']\\n        max_ssim = ckp['max_ssim']\\n        max_psnr = ckp['max_psnr']\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='psnrs = ckp[\\'psnrs\\']\\n        ssims = ckp[\\'ssims\\']\\n        print(f\\'Resuming training from step: {start_step} ***\\')\\n    else :\\n        print(\\'Training from scratch *** \\')\\n    for step in range(start_step+1, steps+1):\\n        net.train()\\n        accumulation_steps = 4\\n        lr = learning_rate\\n        if not no_lr_sche:\\n            lr = lr_schedule_cosdecay(step,T)\\n            for param_group in optim.param_groups:\\n                param_group[\"lr\"] = lr', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='x, y = next(iter(loader_train))\\n        x = x.to(device); y = y.to(device)\\n        torch.cuda.empty_cache()\\n        out = net(x)\\n        loss = criterion[0](out,y)\\n#         loss = loss / accumulation_steps\\n#             loss.backward()  # Accumulate gradients\\n#             if (i + 1) % accumulation_steps == 0:  # Perform optimizer step every accumulation_steps\\n#                 optimizer.step()\\n#                 optimizer.zero_grad()\\n        if perloss:', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='if perloss:\\n            loss2 = criterion[1](out,y)\\n            loss = loss + 0.04*loss2', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='loss.backward()', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"optim.step()\\n        optim.zero_grad()\\n        losses.append(loss.item())\\n        print(f'\\\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}',end='',flush=True)\\n        if step % eval_step ==0 :\\n            with torch.no_grad():\\n                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\\n            print(f'\\\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}')\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"ssims.append(ssim_eval)\\n            psnrs.append(psnr_eval)\\n            if ssim_eval > max_ssim and psnr_eval > max_psnr :\\n                max_ssim = max(max_ssim,ssim_eval)\\n                max_psnr = max(max_psnr,psnr_eval)\\n                torch.save({\\n                            'step': step,\\n                            'max_psnr': max_psnr,\\n                            'max_ssim': max_ssim,\\n                            'ssims': ssims,\\n                            'psnrs': psnrs,\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"'losses': losses,\\n                            'model': net.state_dict()\\n                }, model_dir)\\n                print(f'\\\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}')\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"np.save(f'./numpy_files/{model_name}_{steps}_losses.npy',losses)\\n    np.save(f'./numpy_files/{model_name}_{steps}_ssims.npy',ssims)\\n    np.save(f'./numpy_files/{model_name}_{steps}_psnrs.npy',psnrs)\\n\\n%%time\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content=\"loader_train = loaders_[trainset]\\nloader_test = loaders_[testset]\\nnet = models_[network]\\nnet = net.to(device)\\nif device == 'cuda':\\n    net = torch.nn.DataParallel(net)\\n    cudnn.benchmark = True\\ncriterion = []\\ncriterion.append(nn.L1Loss().to(device))\\nif perloss:\\n    vgg_model = vgg16(pretrained=True).features[:16]\\n    vgg_model = vgg_model.to(device)\\n    for param in vgg_model.parameters():\\n        param.requires_grad = False\\n    criterion.append(PerLoss(vgg_model).to(device))\", metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='optimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\\noptimizer.zero_grad()\\ntrain(net, loader_train, loader_test, optimizer, criterion)', metadata={'source': 'test_repo\\\\src\\\\train.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class PALayer(nn.Module):\\n    def __init__(self, channel):\\n        super(PALayer, self).__init__()\\n        self.pa = nn.Sequential(\\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\\n                nn.ReLU(inplace=True),\\n                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\\n                nn.Sigmoid()\\n        )\\n    def forward(self, x):\\n        y = self.pa(x)\\n        return x * y', metadata={'source': 'test_repo\\\\src\\\\model\\\\attention_mechanisms.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class CALayer(nn.Module):\\n    def __init__(self, channel):\\n        super(CALayer, self).__init__()\\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\\n        self.ca = nn.Sequential(\\n                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\\n                nn.ReLU(inplace=True),\\n                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\\n                nn.Sigmoid()\\n        )', metadata={'source': 'test_repo\\\\src\\\\model\\\\attention_mechanisms.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def forward(self, x):\\n        y = self.avg_pool(x)\\n        y = self.ca(y)\\n        return x * y', metadata={'source': 'test_repo\\\\src\\\\model\\\\attention_mechanisms.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class EfficientAttention(nn.Module):\\n    def __init__(self, channel):\\n        super(EfficientAttention, self).__init__()\\n        self.conv1 = nn.Conv2d(channel, channel, kernel_size=1, bias=False)\\n        self.conv2 = nn.Conv2d(channel, channel, kernel_size=1, bias=False)\\n        self.sigmoid = nn.Sigmoid()\\n    \\n    def forward(self, x):\\n        attn_map = self.sigmoid(self.conv1(x))\\n        refined = attn_map * self.conv2(x)\\n        return refined', metadata={'source': 'test_repo\\\\src\\\\model\\\\attention_mechanisms.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class Block(nn.Module):\\n    def __init__(self, conv, dim, kernel_size):\\n        super(Block, self).__init__()\\n        self.conv1 = conv(dim, dim, kernel_size, bias=True)\\n        self.act1 = nn.ReLU(inplace=True)\\n        self.conv2 = conv(dim, dim, kernel_size, bias=True)\\n        \\n        self.calayer = CALayer(dim) \\n        self.palayer = PALayer(dim)  \\n        self.efficient_attention = EfficientAttention(dim) \\n        self.progressive_refinement = ProgressiveAttentionRefinement(dim)', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def forward(self, x):\\n        res = self.act1(self.conv1(x))\\n        res = res + x\\n        \\n        res = self.conv2(res)\\n        \\n        res = self.calayer(res)\\n        res = self.palayer(res)\\n        res = self.efficient_attention(res)\\n        res = self.progressive_refinement(res)\\n        \\n        res += x\\n        return res', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class Group(nn.Module):\\n    def __init__(self, conv, dim, kernel_size, blocks):\\n        super(Group, self).__init__()\\n        modules = [Block(conv, dim, kernel_size) for _ in range(blocks)]\\n        modules.append(conv(dim, dim, kernel_size))\\n        self.gp = nn.Sequential(*modules)\\n\\n    def forward(self, x):\\n        res = self.gp(x)\\n        res += x\\n        return res', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class FFA(nn.Module):\\n    def __init__(self, gps, blocks, conv=default_conv):\\n        super(FFA, self).__init__()\\n        self.gps = gps\\n        self.dim = 64\\n        kernel_size = 3\\n        pre_process = [conv(3, self.dim, kernel_size)]\\n        assert self.gps == 3\\n        self.g1 = Group(conv, self.dim, kernel_size, blocks=blocks)\\n        self.g2 = Group(conv, self.dim, kernel_size, blocks=blocks)\\n        self.g3 = Group(conv, self.dim, kernel_size, blocks=blocks)', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='self.ca = nn.Sequential(\\n            nn.AdaptiveAvgPool2d(1),\\n            nn.Conv2d(self.dim * self.gps, self.dim // 16, 1, padding=0),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(self.dim // 16, self.dim * self.gps, 1, padding=0, bias=True),\\n            nn.Sigmoid()\\n        )\\n        self.palayer = PALayer(self.dim)', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='post_process = [\\n            conv(self.dim, self.dim, kernel_size),\\n            conv(self.dim, 3, kernel_size)\\n        ]\\n\\n        self.pre = nn.Sequential(*pre_process)\\n        self.post = nn.Sequential(*post_process)', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def forward(self, x1):\\n        x = self.pre(x1)\\n        res1 = self.g1(x)\\n        res2 = self.g2(res1)\\n        res3 = self.g3(res2)\\n        w = self.ca(torch.cat([res1, res2, res3], dim=1))\\n        w = w.view(-1, self.gps, self.dim)[:, :, :, None, None]\\n        out = w[:, 0, :] * res1 + w[:, 1, :] * res2 + w[:, 2, :] * res3\\n        out = self.palayer(out)\\n        x = self.post(out)\\n        return x + x1', metadata={'source': 'test_repo\\\\src\\\\model\\\\ffa_net.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='class ProgressiveAttentionRefinement(nn.Module):\\n    def __init__(self, channels):\\n        super(ProgressiveAttentionRefinement, self).__init__()\\n        self.ca = nn.Sequential(\\n            nn.Conv2d(channels, channels // 8, kernel_size=1, bias=True),\\n            nn.ReLU(inplace=True),\\n            nn.Conv2d(channels // 8, channels, kernel_size=1, bias=True),\\n            nn.Sigmoid()\\n        )\\n        self.pa = nn.Sequential(\\n            nn.Conv2d(channels, 1, kernel_size=1, bias=True),', metadata={'source': 'test_repo\\\\src\\\\model\\\\progressive_attention.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='nn.Sigmoid()\\n        )\\n    \\n    def forward(self, x):\\n        ca_weight = self.ca(x)\\n        pa_weight = self.pa(x)\\n        return x * ca_weight * pa_weight', metadata={'source': 'test_repo\\\\src\\\\model\\\\progressive_attention.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def tensorShow(tensors, titles=None):\\n    fig = plt.figure()\\n    for tensor, title, i in zip(tensors, titles, range(len(tensors))):\\n        img = make_grid(tensor)\\n        npimg = img.numpy()\\n        ax = fig.add_subplot(211 + i)\\n        ax.imshow(np.transpose(npimg, (1, 2, 0)))\\n        ax.set_title(title)\\n    plt.show()\\n\\ndef lr_schedule_cosdecay(t, T, init_lr=learning_rate):\\n    lr = 0.5 * (1 + math.cos(t * math.pi / T)) * init_lr\\n    return lr', metadata={'source': 'test_repo\\\\src\\\\utils\\\\helpers.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def gaussian(window_size, sigma):\\n    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\\n    return gauss / gauss.sum()\\n\\ndef create_window(window_size, channel):\\n    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\\n    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\\n    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\\n    return window', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def _ssim(img1, img2, window, window_size, channel, size_average=True):\\n    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\\n    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\\n    mu1_sq = mu1.pow(2)\\n    mu2_sq = mu2.pow(2)\\n    mu1_mu2 = mu1 * mu2\\n    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\\n    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\\n    C1 = 0.01 ** 2\\n    C2 = 0.03 ** 2\\n    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='if size_average:\\n        return ssim_map.mean()\\n    else:\\n        return ssim_map.mean(1).mean(1).mean(1)', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def ssim(img1, img2, window_size=11, size_average=True):\\n    img1=torch.clamp(img1,min=0,max=1)\\n    img2=torch.clamp(img2,min=0,max=1)\\n    (_, channel, _, _) = img1.size()\\n    window = create_window(window_size, channel)\\n    if img1.is_cuda:\\n        window = window.cuda(img1.get_device())\\n    window = window.type_as(img1)\\n    return _ssim(img1, img2, window, window_size, channel, size_average)', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>}),\n",
       " Document(page_content='def psnr(pred, gt):\\n    pred=pred.clamp(0,1).cpu().numpy()\\n    gt=gt.clamp(0,1).cpu().numpy()\\n    imdff = pred - gt\\n    rmse = math.sqrt(np.mean(imdff ** 2))\\n    if rmse == 0:\\n        return 100\\n    return 20 * math.log10( 1.0 / rmse)', metadata={'source': 'test_repo\\\\src\\\\utils\\\\metrics.py', 'language': <Language.PYTHON: 'python'>})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f431d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82172fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc6b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b06e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c20f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event client_start: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00450d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d39fe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6913831",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm = llm, memory_key = \"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbed2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"K\":8}), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfac7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is PerLoss Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fca740af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26a3baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PerLoss class is a subclass of torch.nn.Module used for defining a perceptual loss function. It takes a VGG model as input and is used for calculating perceptual loss in neural network training.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c800ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
